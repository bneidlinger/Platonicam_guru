# ğŸ“¹ Surveillance Design Assistant

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-green.svg)](https://ollama.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-UI-FF4B4B.svg)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A **local-first RAG (Retrieval-Augmented Generation) system** for Physical Security Systems Engineers. Parse vendor PDFs from Hanwha, Axis, and Bosch to get instant design intelligenceâ€”all running on your machine with no cloud dependencies.

> **Design Principle:** LLMs handle summarization and natural language. Metadata handles computation. POE budgets come from extracted dataâ€”never hallucinated.

---

## âœ¨ Features

### ğŸ¤– RAG-Powered Chat
- Natural language queries against your camera documentation
- Automatic query classification (POE, accessories, comparisons, specs)
- Source citations with every response
- Conversation memory for follow-up questions

### âš¡ POE Budget Calculator
- Extracts power consumption from datasheets via regex
- Calculates project totals from verified metadataâ€”not LLM generation
- Tracks PoE class (Class 0-4) for switch compatibility

### ğŸ“· Project Mode
- Build camera lists for system designs
- Real-time POE budget tracking
- Export to CSV/JSON for BOMs and proposals

### ğŸ” Smart Search
- Semantic search across all vendor documentation
- Filter by vendor, document type, or model number
- Image extraction for visual accessory verification

### ğŸ  100% Local
- Runs entirely on your machine
- Your PDFs never leave your network
- No API costs or rate limits
- Works offline once models are downloaded

---

## ğŸ–¥ï¸ Screenshots

<details>
<summary>Click to expand screenshots</summary>

### Chat Interface
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“¹ Surveillance Design Assistant                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  You: What is the power consumption of the XNV-8080R?       â”‚
â”‚                                                             â”‚
â”‚  Assistant: The Hanwha XNV-8080R has a maximum power        â”‚
â”‚  consumption of **25.5W** (PoE++ Class 4).                  â”‚
â”‚                                                             â”‚
â”‚  [Source: XNV-8080R_Datasheet.pdf, Page 2]                  â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“‹ Project Mode          â”‚  âš¡ POE Budget                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚  â€¢ XNV-8080R    x4        â”‚  XNV-8080R: 25.5W Ã— 4 = 102W   â”‚
â”‚  â€¢ P3265-LVE   x8        â”‚  P3265-LVE: 12.9W Ã— 8 = 103.2W â”‚
â”‚                           â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚  [Export CSV] [JSON]      â”‚  TOTAL: 205.2W                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</details>

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Ollama** - [Download here](https://ollama.com/download)
- **8GB+ RAM** (16GB recommended for larger models)
- **GPU optional** but recommended for faster inference

### 1. Clone & Install

```bash
git clone https://github.com/bneidlinger/platonicam_guru.git
cd platonicam_guru

# Create virtual environment
python -m venv venv

# Activate (Windows)
.\venv\Scripts\activate

# Activate (macOS/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Download Ollama Models

```bash
# Embedding model (required)
ollama pull nomic-embed-text

# Chat model (choose based on your hardware)
ollama pull llama3.1:8b        # Recommended (6GB VRAM)
# OR
ollama pull phi3:mini          # Lower VRAM option (3GB)
# OR
ollama pull llama3.2:3b        # Budget GPU (4GB)
```

### 3. Add Your PDFs

```
data/pdfs/
â”œâ”€â”€ hanwha/
â”‚   â”œâ”€â”€ XNV-8080R_Datasheet.pdf
â”‚   â””â”€â”€ XNP-6400RW_Installation.pdf
â”œâ”€â”€ axis/
â”‚   â””â”€â”€ P3265-LVE_Datasheet.pdf
â””â”€â”€ bosch/
    â””â”€â”€ NBE-3502-AL_Manual.pdf
```

### 4. Ingest Documents

```bash
# Process all PDFs
python -m src.ingest

# Or specific vendor
python -m src.ingest --vendor hanwha
```

### 5. Launch the App

```bash
python run_app.py
```

Open http://localhost:8501 in your browser.

---

## ğŸ“– Usage

### Web UI (Recommended)

```bash
python run_app.py
```

**Pages:**
- **Chat** - Ask questions, get answers with citations
- **Ingestion** - Upload PDFs, manage database
- **Database** - Search, browse, POE lookup

### CLI Chat

```bash
# Interactive mode with streaming
python -m src.chat

# Single query
python -m src.chat "What mount fits the XNV-8080R?"

# With vendor filter
python -m src.chat --vendor hanwha
```

### CLI Search

```bash
# Semantic search
python -m src.search "outdoor vandal dome 4K"

# POE budget calculation
python -m src.search --poe "XNV-8080R,P3265-LVE,NBE-3502-AL"

# Interactive mode
python -m src.search -i
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER QUERY                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUERY CLASSIFICATION                          â”‚
â”‚         (POE / Accessory / Comparison / Spec / General)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EMBEDDING       â”‚ â”‚  METADATA    â”‚ â”‚  CONVERSATION    â”‚
â”‚  (nomic-embed)   â”‚ â”‚  LOOKUP      â”‚ â”‚  MEMORY          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚               â”‚               â”‚
              â–¼               â–¼               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CHROMADB VECTOR STORE                       â”‚
â”‚                   (Semantic Search + Filtering)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CONTEXT INJECTION                            â”‚
â”‚              (Retrieved docs + Verified metadata)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OLLAMA LLM                                  â”‚
â”‚                    (llama3.1:8b)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESPONSE + CITATIONS                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Metadata Extraction

The system extracts structured data from PDFs using regex patterns:

| Field | Pattern | Example |
|-------|---------|---------|
| Model Number | `[A-Z]{1,4}-[A-Z0-9]{4,10}` | XNV-8080R, P3265-LVE |
| POE Wattage | `\d{1,2}\.?\d?\s?W` | 25.5W, 12.9 W |
| POE Class | `Class\s?[0-4]` | Class 4 |
| IP Rating | `IP[0-9]{2}` | IP66, IP67 |
| Brand | Hanwha, Axis, Bosch, etc. | Wisenet â†’ Hanwha |

**Tiered Schema:**
- **Tier 1 (Document):** vendor, doc_type, source_file
- **Tier 2 (Engineering):** model_num, poe_wattage, poe_class, brand
- **Tier 3 (Visual):** image_refs, page_num, chunk_index

---

## ğŸ› ï¸ Configuration

Edit `config/settings.py`:

```python
class Settings:
    # Chunk settings
    CHUNK_SIZE = 1200
    CHUNK_OVERLAP = 150

    # Models
    EMBEDDING_MODEL = "nomic-embed-text"
    CHAT_MODEL = "llama3.1:8b"
    TEMPERATURE = 0.2

    # Retrieval
    TOP_K = 5
```

---

## ğŸ“ Project Structure

```
platonicam_guru/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py          # Main chat UI
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_ğŸ“_Ingestion.py     # PDF upload
â”‚       â””â”€â”€ 2_ğŸ”_Database.py      # Search & browse
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py         # PyMuPDF extraction
â”‚   â”‚   â”œâ”€â”€ metadata_extractor.py # Regex patterns
â”‚   â”‚   â””â”€â”€ batch_processor.py    # Bulk processing
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ ollama_embed.py       # Vector generation
â”‚   â”œâ”€â”€ vectorstore/
â”‚   â”‚   â””â”€â”€ chroma_store.py       # ChromaDB operations
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ chain.py              # Main orchestrator
â”‚   â”‚   â”œâ”€â”€ retriever.py          # Context retrieval
â”‚   â”‚   â”œâ”€â”€ prompts.py            # System prompts
â”‚   â”‚   â”œâ”€â”€ memory.py             # Conversation state
â”‚   â”‚   â””â”€â”€ llm_client.py         # Ollama interface
â”‚   â”œâ”€â”€ ingest.py                 # Ingestion CLI
â”‚   â”œâ”€â”€ search.py                 # Search CLI
â”‚   â””â”€â”€ chat.py                   # Chat CLI
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py               # Configuration
â”œâ”€â”€ tests/                        # pytest suite
â”œâ”€â”€ docs/                         # Setup guides (HTML)
â”œâ”€â”€ data/pdfs/                    # Your PDFs (gitignored)
â”œâ”€â”€ assets/images/                # Extracted images (gitignored)
â”œâ”€â”€ chroma_db/                    # Vector store (gitignored)
â””â”€â”€ requirements.txt
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# With coverage
pytest --cov=src

# Specific module
pytest tests/test_metadata_extractor.py -v

# Tests requiring Ollama (skipped if unavailable)
pytest tests/test_ollama_embed.py -v
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.com/) - Local LLM inference
- [ChromaDB](https://www.trychroma.com/) - Vector database
- [LangChain](https://langchain.com/) - Text splitting
- [PyMuPDF](https://pymupdf.readthedocs.io/) - PDF parsing
- [Streamlit](https://streamlit.io/) - Web UI framework

---

## ğŸ“¬ Support

- **Issues:** [GitHub Issues](https://github.com/yourusername/platonicam_guru/issues)
- **Discussions:** [GitHub Discussions](https://github.com/yourusername/platonicam_guru/discussions)

---

<p align="center">
  Built for Physical Security Engineers who need answers, not guesses.
</p>
